---
layout: post
title: "My lessons learned Building an NLP-to-SQL Query Engine"
tags: [NLP, OpenAI, FastAPI, AWS, Athena, Docker, Kubernetes, CI/CD]
categories: []
---
**GitHub Repository:** [View on GitHub](https://github.com/itsAshna/nlp-to-sql-queries)

### Introduction  
Over the past few weeks, I embarked on a project that combined my interests in natural language processing, cloud infrastructure, and backend engineering. The goal? To make it possible for non-technical users to query databases using simple English sentences — no SQL knowledge required.  

It started as a side project and evolved into a fully deployed, production-ready cloud service with CI/CD, Kubernetes orchestration, and some fun debugging along the way.  

---

### Problem  
Data is everywhere, but not everyone knows SQL. Business users, analysts, and even developers often wish they could “just ask” a dataset a question without worrying about syntax or schema details. The challenge was to create a service that:  
- Accepts a natural language question  
- Translates it into SQL using AI  
- Executes it against a live dataset  
- Returns results in a clean, accessible format  

---

### Approach  

#### 1. AI-Powered Translation
I used OpenAI’s API to translate natural language into SQL. This step was critical — the model needed schema awareness, so I fed it the database table structures alongside the query prompt.  

#### 2. Server & API
FastAPI served as the application backend, exposing an `/ask` endpoint for clients to submit questions. Swagger docs (`/docs`) provided an interactive interface for testing.  

##3# 3. Query Execution 
The generated SQL was executed on Amazon Athena, reading from an S3-backed dataset (Northwind database). Results were streamed back in JSON format.  

#### 4. Deployment & Scalability  
The entire system was containerized with Docker, then deployed to AWS EKS (Elastic Kubernetes Service). A LoadBalancer service exposed it publicly.  

#### 5. Automation with GitHub Actions
CI/CD handled Docker image builds and pushes to Amazon ECR, automatically triggering new deployments on EKS. This meant every code change was deployed with minimal manual intervention.  

---

### Results  
After deployment, I had a fully functional API where you could send a POST request like:  

```json
{"question": "Show me all products"}
```

and get real database results back — without writing a single line of SQL.

The service was public via an AWS Load Balancer URL, making it easy for anyone to try it out.

---

### Challenges

#### 1. Authentication & Secrets

Ensuring AWS and OpenAI credentials were securely passed into the container required setting up Kubernetes secrets and GitHub Actions secrets properly.

#### 2. Config & Imports After Refactor

I had to rename my project from `nlp-agent` to `nlp_agent` as caused broken imports until I updated all references — including in the Docker build and GitHub Actions.

#### 3. ARM vs. AMD64 Build Issue

This was the big one. My M1 Mac (ARM64) built Docker images that failed to run on AWS EKS nodes (AMD64). The fix was to explicitly set the build platform in GitHub Actions:

```yaml
docker buildx build --platform linux/amd64 ...
```

This ensured images ran reliably in the target cloud environment.

#### 4. Cost Awareness

Kubernetes clusters on AWS aren’t free — so after testing, I had to tear down the cluster, ECR repos, and S3 data to avoid ongoing charges.

---

### What I Solved

* Made structured data queryable with plain English
* Automated deployment from code commit to cloud service
* Resolved ARM64 → AMD64 Docker compatibility issues
* Learned the importance of resource cleanup in cloud projects

---

### Conclusion

This project brought together multiple domains — AI, cloud infrastructure, DevOps, and backend APIs. It was a reminder that building AI-powered applications isn’t just about the model — it’s about making it accessible, scalable, and cost-effective.


---

If you’ve ever wanted to turn “English into SQL” and deploy it to the cloud, I hope this breakdown helps. And if you’re working on an M1 Mac — trust me, check your build platform before you spend hours debugging.
