<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://www.ashnasarora.com/feed.xml" rel="self" type="application/atom+xml"/><link href="https://www.ashnasarora.com/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-08-18T01:03:42+00:00</updated><id>https://www.ashnasarora.com/feed.xml</id><title type="html">blank</title><subtitle>Ashna&apos;s Website </subtitle><entry><title type="html">Hands‑on with ChatGPT 5</title><link href="https://www.ashnasarora.com/2025/08/11/blog.html" rel="alternate" type="text/html" title="Hands‑on with ChatGPT 5"/><published>2025-08-11T00:00:00+00:00</published><updated>2025-08-11T00:00:00+00:00</updated><id>https://www.ashnasarora.com/2025/08/11/blog</id><content type="html" xml:base="https://www.ashnasarora.com/2025/08/11/blog.html"><![CDATA[<p>ChatGPT 5 isn’t just a “new model number.” It brings deeper reasoning, better routing between fast and thinking modes, agentic browsing/automation, and quality‑of‑life tools that make it useful <em>day to day</em>. Below are the most effective workflows I’ve tested — with copy‑paste prompts you can use as a starting point.</p> <blockquote> <p><strong>Tip:</strong> In ChatGPT, select <strong>GPT‑5</strong>. It decides when to switch into <strong>Thinking</strong> for harder tasks. You don’t have to toggle it manually — but you <em>can</em> ask it to “think step‑by‑step and verify each claim,” which nudges the deeper mode.</p> </blockquote> <hr/> <h4 id="1-research-that-actually-finishes-deep-research--agent">1) Research that actually finishes (Deep Research + Agent)</h4> <p><strong>When to use:</strong> Market scans, lit reviews, product comps, due diligence.</p> <p><strong>How I run it</strong></p> <ol> <li>Start with:<br/> <em>“Act as a research lead. Create a plan first: sources to check, search operators, evaluation criteria. Then execute the plan. Log sources and a confidence score per finding.”</em></li> <li>Add constraints: timeframe, geographies, competitor list, must‑answer questions.</li> <li>Let <strong>Agent mode</strong> browse, open pages, and extract facts. Ask for <strong>source‑linked evidence</strong> and a short <strong>“what this means”</strong> verdict after each section.</li> <li>Finish with: <em>“Give me a one‑page brief + a 6‑slide outline, and export a table of citations (title, author, date, URL, why it’s credible).”</em></li> </ol> <p><strong>Deliverables I request</strong></p> <ul> <li>1‑pager brief (markdown)</li> <li>Slide outline with titles + talking points</li> <li>CSV/Sheet with sources</li> </ul> <hr/> <h4 id="2-coding-partner-that-ships">2) Coding partner that ships</h4> <p><strong>When to use:</strong> Greenfield features, refactors, tests, debugging.</p> <p><strong>Prompts that work</strong></p> <ul> <li><em>“Here’s the repo context (paste key files). Propose an implementation plan with milestones. Guardrails: lint rules, test coverage target, perf budget.”</em></li> <li><em>“Write the module <strong>and</strong> tests. Then run a code review on your own diff and propose simplifications.”</em></li> <li><em>“Switch to Thinking and reason about edge cases before writing code. Produce a checklist, then implement.”</em></li> </ul> <p><strong>Patterns I like</strong></p> <ul> <li>Ask for a <strong>fails‑first test</strong> plan before code.</li> <li>Have it <strong>explain trade‑offs</strong> (libraries, complexity, perf) and commit to one.</li> <li>Request a <strong>migration plan</strong> (scripts, rollback, observability).</li> </ul> <hr/> <h4 id="3-writing-that-lands">3) Writing that lands</h4> <p><strong>Use cases:</strong> Emails, briefs, PRDs, blogs, job posts, performance reviews.</p> <p><strong>Prompt frame</strong></p> <blockquote> <p><em>“Audience: hiring managers in data teams. Goal: book intro calls. Voice: warm, direct, credible. Tone: concrete, no fluff. Constraints: 140–180 words, 1 CTA, at most 1 emoji. Draft 3 options, then critique and combine into a final.”</em></p> </blockquote> <p><strong>Polish</strong></p> <ul> <li><em>“Rewrite with a stronger hook and a single through‑line.”</em></li> <li><em>“List 5 headlines with different angles (authority, curiosity, numbers, contrarian, social proof).”</em></li> <li><em>“Fact‑check every claim; add inline citations or mark as anecdotal.”</em></li> </ul> <hr/> <h4 id="4-ongoing-work-you-dont-want-to-babysit-tasks">4) Ongoing work you don’t want to babysit (Tasks)</h4> <p>Set <strong>Tasks</strong> for recurring work so ChatGPT runs on its own and pings you with results.</p> <p><strong>Ideas</strong></p> <ul> <li>Daily <strong>industry brief</strong> at 8am with 5 links and “why it matters.”</li> <li>Weekly <strong>lead list</strong> from public pages (company, role, location) exported as CSV.</li> <li>Monthly <strong>resume refresh</strong>: summarize new projects, quantify outcomes, update bullets.</li> <li><strong>Learning plan</strong>: 3 micro‑lessons per week + spaced‑repetition quiz.</li> </ul> <p><strong>One‑liner you can paste</strong></p> <blockquote> <p><em>“Every weekday at 8:00, scan top sources for [YOUR TOPIC]. Send a 6‑bullet briefing (50–80 chars per bullet) with links, a 2‑sentence analysis, and a confidence score. If nothing meaningful, say ‘no significant updates’.”</em></p> </blockquote> <hr/> <h4 id="5-agentic-execution-browse-log-in-produce-deliverables">5) Agentic execution (browse, log in, produce deliverables)</h4> <p>For multi‑step asks that mix browsing, data extraction, analysis, and output:</p> <p><strong>Prompt skeleton</strong></p> <ol> <li><em>“Plan out the steps before acting.”</em></li> <li><em>“While browsing, save a log of visited pages (URL, title, why relevant).”</em></li> <li><em>“If a login is needed, prompt me; do not store credentials.”</em></li> <li><em>“Create deliverables: (a) editable slide deck, (b) spreadsheet, (c) summary memo.”</em></li> </ol> <p><strong>Great tasks</strong></p> <ul> <li>Competitor teardown → deck + scorecard</li> <li>Vendor shortlist → spreadsheet with weighted criteria</li> <li>Content calendar → CSV + Notion‑ready markdown</li> </ul> <hr/> <h4 id="6-better-prompting-in-gpt5-quick-rules">6) Better prompting in GPT‑5 (quick rules)</h4> <ul> <li><strong>Set the role, audience, goal, and constraints.</strong></li> <li><strong>Ask it to plan first, then execute.</strong></li> <li><strong>Request verification:</strong> citations, tests, or lint rules.</li> <li><strong>Use iterations:</strong> “v1 → critique → v2.”</li> <li><strong>Be explicit about formatting:</strong> tables, JSON, CSV, markdown sections.</li> </ul> <p>Copy‑paste starter:</p> <blockquote> <p><em>“You are my “role”. Audience: “who”. Goal: “what”. Constraints: length, tone, format. First: propose a plan with steps, risks, and acceptance criteria. Then execute. Use Thinking for non-trivial reasoning. End with a QA checklist.”</em></p> </blockquote> <hr/> <h4 id="7-api--developer-notes-mini">7) API / developer notes (mini)</h4> <ul> <li>In the API, GPT‑5 is strong at <strong>agentic</strong> and <strong>coding</strong> tasks. Reach for it when you need end‑to‑end implementations, analysis, or tool use.</li> <li>Consider routing trivial tasks to lighter models; use GPT‑5 for the complex parts.</li> <li>Capture <strong>traces</strong> and <strong>evals</strong> so you can compare Chat vs. Thinking on your use case.</li> </ul> <hr/> <h4 id="final-thoughts">Final thoughts</h4> <p>Day‑to‑day usefulness comes from <em>workflow design</em> more than raw model horsepower. With ChatGPT 5, the biggest gains show up when you let it plan first, verify outputs, and automate the routines so you can focus on judgment calls.</p>]]></content><author><name></name></author><category term="ChatGPT"/><category term="GPT-5"/><category term="deep research"/><category term="agents"/><category term="tasks"/><category term="prompting"/><summary type="html"><![CDATA[ChatGPT 5 isn’t just a “new model number.” It brings deeper reasoning, better routing between fast and thinking modes, agentic browsing/automation, and quality‑of‑life tools that make it useful day to day. Below are the most effective workflows I’ve tested — with copy‑paste prompts you can use as a starting point.]]></summary></entry><entry><title type="html">My lessons learned Building an NLP-to-SQL Query Engine</title><link href="https://www.ashnasarora.com/2025/08/10/blog.html" rel="alternate" type="text/html" title="My lessons learned Building an NLP-to-SQL Query Engine"/><published>2025-08-10T00:00:00+00:00</published><updated>2025-08-10T00:00:00+00:00</updated><id>https://www.ashnasarora.com/2025/08/10/blog</id><content type="html" xml:base="https://www.ashnasarora.com/2025/08/10/blog.html"><![CDATA[<p><strong>GitHub Repository:</strong> <a href="https://github.com/itsAshna/nlp-to-sql-queries">View on GitHub</a></p> <h3 id="introduction">Introduction</h3> <p>Over the past few weeks, I embarked on a project that combined my interests in natural language processing, cloud infrastructure, and backend engineering. The goal? To make it possible for non-technical users to query databases using simple English sentences — no SQL knowledge required.</p> <p>It started as a side project and evolved into a fully deployed, production-ready cloud service with CI/CD, Kubernetes orchestration, and some fun debugging along the way.</p> <hr/> <h3 id="problem">Problem</h3> <p>Data is everywhere, but not everyone knows SQL. Business users, analysts, and even developers often wish they could “just ask” a dataset a question without worrying about syntax or schema details. The challenge was to create a service that:</p> <ul> <li>Accepts a natural language question</li> <li>Translates it into SQL using AI</li> <li>Executes it against a live dataset</li> <li>Returns results in a clean, accessible format</li> </ul> <hr/> <h3 id="approach">Approach</h3> <h4 id="1-ai-powered-translation">1. AI-Powered Translation</h4> <p>I used OpenAI’s API to translate natural language into SQL. This step was critical — the model needed schema awareness, so I fed it the database table structures alongside the query prompt.</p> <h4 id="2-server--api">2. Server &amp; API</h4> <p>FastAPI served as the application backend, exposing an <code class="language-plaintext highlighter-rouge">/ask</code> endpoint for clients to submit questions. Swagger docs (<code class="language-plaintext highlighter-rouge">/docs</code>) provided an interactive interface for testing.</p> <p>##3# 3. Query Execution The generated SQL was executed on Amazon Athena, reading from an S3-backed dataset (Northwind database). Results were streamed back in JSON format.</p> <h4 id="4-deployment--scalability">4. Deployment &amp; Scalability</h4> <p>The entire system was containerized with Docker, then deployed to AWS EKS (Elastic Kubernetes Service). A LoadBalancer service exposed it publicly.</p> <h4 id="5-automation-with-github-actions">5. Automation with GitHub Actions</h4> <p>CI/CD handled Docker image builds and pushes to Amazon ECR, automatically triggering new deployments on EKS. This meant every code change was deployed with minimal manual intervention.</p> <hr/> <h3 id="results">Results</h3> <p>After deployment, I had a fully functional API where you could send a POST request like:</p> <div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w"> </span><span class="nl">"question"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Show me all products"</span><span class="w"> </span><span class="p">}</span><span class="w">
</span></code></pre></div></div> <p>and get real database results back — without writing a single line of SQL.</p> <p>The service was public via an AWS Load Balancer URL, making it easy for anyone to try it out.</p> <hr/> <h3 id="challenges">Challenges</h3> <h4 id="1-authentication--secrets">1. Authentication &amp; Secrets</h4> <p>Ensuring AWS and OpenAI credentials were securely passed into the container required setting up Kubernetes secrets and GitHub Actions secrets properly.</p> <h4 id="2-config--imports-after-refactor">2. Config &amp; Imports After Refactor</h4> <p>I had to rename my project from <code class="language-plaintext highlighter-rouge">nlp-agent</code> to <code class="language-plaintext highlighter-rouge">nlp_agent</code> as caused broken imports until I updated all references — including in the Docker build and GitHub Actions.</p> <h4 id="3-arm-vs-amd64-build-issue">3. ARM vs. AMD64 Build Issue</h4> <p>This was the big one. My M1 Mac (ARM64) built Docker images that failed to run on AWS EKS nodes (AMD64). The fix was to explicitly set the build platform in GitHub Actions:</p> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="s">docker buildx build --platform linux/amd64 ...</span>
</code></pre></div></div> <p>This ensured images ran reliably in the target cloud environment.</p> <h4 id="4-cost-awareness">4. Cost Awareness</h4> <p>Kubernetes clusters on AWS aren’t free — so after testing, I had to tear down the cluster, ECR repos, and S3 data to avoid ongoing charges.</p> <hr/> <h3 id="what-i-solved">What I Solved</h3> <ul> <li>Made structured data queryable with plain English</li> <li>Automated deployment from code commit to cloud service</li> <li>Resolved ARM64 → AMD64 Docker compatibility issues</li> <li>Learned the importance of resource cleanup in cloud projects</li> </ul> <hr/> <h3 id="conclusion">Conclusion</h3> <p>This project brought together multiple domains — AI, cloud infrastructure, DevOps, and backend APIs. It was a reminder that building AI-powered applications isn’t just about the model — it’s about making it accessible, scalable, and cost-effective.</p> <hr/> <p>If you’ve ever wanted to turn “English into SQL” and deploy it to the cloud, I hope this breakdown helps. And if you’re working on an M1 Mac — trust me, check your build platform before you spend hours debugging.</p>]]></content><author><name></name></author><category term="NLP"/><category term="OpenAI"/><category term="FastAPI"/><category term="AWS"/><category term="Athena"/><category term="Docker"/><category term="Kubernetes"/><category term="CI/CD"/><summary type="html"><![CDATA[GitHub Repository: View on GitHub]]></summary></entry></feed>